import os
import asyncio
import logging
from datetime import datetime
import traceback

# ðŸš€ PERFORMANCE BOOST: Use orjson instead of json (3x faster)
try:
    import orjson as json
    def json_dumps(data):
        return json.dumps(data).decode('utf-8')
    def json_loads(data):
        return json.loads(data)
    logger = logging.getLogger(__name__)
    logger.info("ðŸš€ Using orjson for 3x faster JSON processing")
except ImportError:
    import json
    def json_dumps(data):
        return json.dumps(data)
    def json_loads(data):
        return json.loads(data)
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ orjson not available, using standard json")

# Cloud Functions imports
import functions_framework
from flask import Request 

# Setup logging first
def setup_logging():
    """Setup logging for Cloud Functions"""
    logging.basicConfig(
        level=logging.INFO,
        format='{"severity": "%(levelname)s", "message": "%(message)s", "timestamp": "%(asctime)s"}',
        force=True
    )
    logging.getLogger('werkzeug').setLevel(logging.WARNING)

# Initialize logging
setup_logging()

# Import our services
try:
    from utils.config import Config
    from handlers.analysis_handler import analysis_handler
    from services.notifications.notifications import telegram_service
    logger.info("Successfully imported all services")
except Exception as e:
    logger.error(f"Failed to import services: {e}")
    logger.error(f"Traceback: {traceback.format_exc()}")

# Global initialization flag
_initialized = False

async def initialize_services():
    """Initialize all services once"""
    global _initialized
    if not _initialized:
        logger.info("Initializing Cloud Function services with orjson...")
        
        try:
            # Validate configuration
            config = Config()
            logger.info(f"BigQuery project: {getattr(config, 'bigquery_project_id', 'Not configured')}")
            logger.info(f"BigQuery configured: {bool(config.bigquery_project_id)}")
            logger.info(f"Alchemy configured: {bool(config.alchemy_api_key)}")
            
            # Initialize analysis handler (includes last run tracker)
            await analysis_handler.initialize()
            
            # Log Telegram configuration status
            if telegram_service.is_configured():
                bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
                chat_id = os.getenv('TELEGRAM_CHAT_ID')
                logger.info(f"Telegram configured - Bot: {bot_token[:10]}...{bot_token[-5:] if len(bot_token) > 15 else '****'}, Chat: {chat_id}")
            else:
                logger.warning("Telegram not configured")
            
            logger.info("Services initialized successfully with orjson performance boost")
            _initialized = True
            
        except Exception as e:
            logger.error(f"Service initialization failed: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            # Don't raise - let the function start but log the error
            _initialized = False

@functions_framework.http
def main(request: Request):
    """Cloud Functions HTTP entry point with orjson performance"""
    
    logger.info("ðŸš€ Cloud Function started with orjson performance boost")
    
    # Initialize services on first request
    try:
        if not _initialized:
            asyncio.run(initialize_services())
    except Exception as e:
        logger.error(f"Service initialization failed: {e}")
        error_response = {
            "error": f"Service initialization failed: {str(e)}",
            "success": False,
            "timestamp": datetime.utcnow().isoformat(),
            "traceback": traceback.format_exc()
        }
        return (json_dumps(error_response), 500, {'Content-Type': 'application/json'})
    
    # Handle CORS preflight
    if request.method == 'OPTIONS':
        headers = {
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',
            'Access-Control-Allow-Headers': 'Content-Type',
            'Access-Control-Max-Age': '3600'
        }
        return ('', 204, headers)
    
    # Set CORS headers for main response
    headers = {
        'Access-Control-Allow-Origin': '*',
        'Content-Type': 'application/json'
    }
    
    try:
        # Handle GET request (health check + status)
        if request.method == 'GET':
            return asyncio.run(handle_health_check(headers))
        
        # Handle POST request (analysis)
        if request.method == 'POST':
            return asyncio.run(handle_analysis_request(request, headers))
        
        # Method not allowed
        return (
            json_dumps({"error": "Method not allowed"}), 
            405, 
            headers
        )
        
    except Exception as e:
        logger.error(f"Function failed: {e}")
        logger.error(f"Function traceback: {traceback.format_exc()}")
        
        error_response = {
            "error": f"Function error: {str(e)}",
            "success": False,
            "timestamp": datetime.utcnow().isoformat(),
            "traceback": traceback.format_exc()
        }
        return (json_dumps(error_response), 500, headers)

async def handle_health_check(headers):
    """Handle GET request for health check"""
    try:
        # Get run history if available
        run_history = await analysis_handler.get_run_history(5)
        
        response = {
            "message": "Crypto Analysis Function with orjson Performance",
            "status": "healthy",
            "version": "8.1.0-orjson",
            "service": "crypto-analysis-cloud-function",
            "timestamp": datetime.utcnow().isoformat(),
            "initialized": _initialized,
            "telegram_configured": telegram_service.is_configured(),
            "database_type": "BigQuery",
            "ai_library": "Enhanced AI",
            "architecture": "modular",
            "performance_boost": "orjson (3x faster JSON)",
            "last_run_tracking": analysis_handler.last_run_tracker and analysis_handler.last_run_tracker.is_available(),
            "recent_runs": run_history,
            "services": {
                "analysis_handler": "âœ“ Initialized" if _initialized else "âœ— Not initialized",
                "telegram_service": "âœ“ Configured" if telegram_service.is_configured() else "âœ— Not configured",
                "last_run_tracker": "âœ“ Available" if analysis_handler.last_run_tracker and analysis_handler.last_run_tracker.is_available() else "âœ— Not available"
            },
            "features": [
                "orjson Performance Boost (3x faster)",
                "Enhanced AI Analysis", 
                "ML Anomaly Detection", 
                "Sentiment Analysis",
                "Whale Coordination Detection",
                "Smart Money Flow Analysis",
                "Telegram notifications",
                "Smart Timing (automatic days_back calculation)",
                "Last Run Tracking (BigQuery)",
                "Contract Address Extraction",
                "Lower Notification Thresholds",
                "Modular Architecture"
            ]
        }
        
        return (json_dumps(response), 200, headers)
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        error_response = {
            "error": f"Health check failed: {str(e)}",
            "success": False,
            "timestamp": datetime.utcnow().isoformat()
        }
        return (json_dumps(error_response), 500, headers)

async def handle_analysis_request(request: Request, headers):
    """Handle POST request for analysis with orjson parsing"""
    try:
        # Get JSON data using orjson for 3x faster parsing
        request_json = request.get_json(silent=True)
        if not request_json:
            return (
                json_dumps({"error": "No JSON data provided"}), 
                400, 
                headers
            )
        
        # Override user settings with lower thresholds for more notifications
        if 'min_alpha_score' not in request_json:
            request_json['min_alpha_score'] = 15.0  # Lowered from 50.0
        else:
            # Ensure it's not too high
            request_json['min_alpha_score'] = min(float(request_json['min_alpha_score']), 25.0)
        
        if 'max_tokens' not in request_json:
            request_json['max_tokens'] = 10  # Increased from 7
        else:
            # Ensure we get more tokens
            request_json['max_tokens'] = max(int(request_json['max_tokens']), 5)
        
        logger.info(f"Running analysis request with enhanced settings: min_score={request_json['min_alpha_score']}, max_tokens={request_json['max_tokens']}")
        
        # Delegate to analysis handler
        result = await analysis_handler.handle_analysis_request(request_json)
        status_code = 200 if result.get('success', False) else 500
        
        # Use orjson for 3x faster response serialization
        return (json_dumps(result), status_code, headers)
        
    except Exception as e:
        logger.error(f"Analysis request failed: {e}")
        logger.error(f"Analysis request traceback: {traceback.format_exc()}")
        
        error_response = {
            "error": str(e),
            "success": False,
            "timestamp": datetime.utcnow().isoformat(),
            "traceback": traceback.format_exc()
        }
        return (json_dumps(error_response), 500, headers)

# For local testing
if __name__ == "__main__":
    logger.info("Starting local test with orjson performance boost")
    asyncio.run(initialize_services())
    print("Function ready for local testing with 3x faster JSON processing.")